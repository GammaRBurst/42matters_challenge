FROM python:3.8
WORKDIR /home
RUN ["mkdir", "app"]
WORKDIR app
ADD main.py .
ADD requirements.txt .
RUN ["pip", "install", "-r", "requirements.txt"]
RUN ["apt-get", "update"]
RUN ["apt-get", "install", "-y", "curl", "tar", "openjdk-11-jre", "openjdk-11-jre-headless"]
RUN ["curl", "https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz", "--output", "spark-3.2.1-bin-hadoop3.2.tgz"]
RUN ["tar", "zxvf", "spark-3.2.1-bin-hadoop3.2.tgz"]
ENV SPARK_HOME=/home/app/spark-3.2.1-bin-hadoop3.2
ENV PATH=$PATH:$SPARK_HOME/bin
ENV PATH=$PATH:$SPARK_HOME/sbin
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH
ENV PATH=$SPARK_HOME/python:$PATH
RUN ["mkdir", "result"]
CMD ["python3", "main.py"]

